{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import re\n",
    "from random import shuffle\n",
    "import random\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_data= pd.read_excel(r\"data/ner_training_data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_char_offset(list_words):\n",
    "    offset = 0\n",
    "    for wrd in list_words:\n",
    "        offset += len(wrd)\n",
    "    offset += len(list_words)\n",
    "    return offset\n",
    "\n",
    "# Function to insert row in the dataframe \n",
    "def Insert_row_(row_number, df, row_value): \n",
    "    # Slice the upper half of the dataframe \n",
    "    df1 = df[0:row_number] \n",
    "   \n",
    "    # Store the result of lower half of the dataframe \n",
    "    df2 = df[row_number:] \n",
    "   \n",
    "    # Inser the row in the upper half dataframe \n",
    "    df1.loc[row_number]=row_value \n",
    "   \n",
    "    # Concat the two dataframes \n",
    "    df_result = pd.concat([df1, df2]) \n",
    "   \n",
    "    # Reassign the index labels \n",
    "    df_result.index = [*range(df_result.shape[0])] \n",
    "   \n",
    "    # Return the updated dataframe \n",
    "    return df_result\n",
    "\n",
    "import inflect\n",
    "import math\n",
    "def get_price_num2word(number):  \n",
    "    p = inflect.engine()\n",
    "    return p.number_to_words(int(number))\n",
    "        \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inflect\n",
    "def augment_price(df_aug_tag,df_all_data,aug_samples,aug_tag,page_num_start=100000):\n",
    "    random.seed(0)\n",
    "    phrases = ['##NUMSTR## dollar',\n",
    "                'USD (##NUM##)',\n",
    "                '$ (##NUM## )',\n",
    "              ]\n",
    "    p = inflect.engine()\n",
    "    num_price_range = [10000,20000,30000,40000]\n",
    "    \n",
    "    list_df_aug = []\n",
    "    for idx in range(aug_samples):\n",
    "        dict_aug_data = {}\n",
    "        rnd_phrase= random.choice(phrases)\n",
    "             \n",
    "        rand_price = random.choice(price)      \n",
    "        price_word =  get_price_num2word(rand_price)\n",
    "        \n",
    "        rnd_phrase=rnd_phrase.replace('##NUM##',str(rand_price))\n",
    "        rnd_phrase=rnd_phrase.replace('##NUMSTR##',price_word)        \n",
    "\n",
    "        df_tmp = df_aug_tag.sample()\n",
    "        df_tmp = df_aug_tag.sample() \n",
    "        idx_page = list(df_tmp['page_num'])[0]\n",
    "        idx_para = list(df_tmp['par_num'])[0]\n",
    "        start_word = list(df_tmp['start_word'])[0]\n",
    "        end_word = list(df_tmp['end_word'])[0]\n",
    "        \n",
    "        df_tmp_para = df_all_data[(df_all_data['page_num']==idx_page) &  (df_all_data['par_num']==idx_para)]\n",
    "        df_tmp_para.reset_index(inplace= True)\n",
    "        print('{}: {} <--> {}'.format(idx,' '.join(list(df_tmp_para.loc[start_word:end_word]['word'])),rnd_phrase))\n",
    "\n",
    "        df_tmp_para['page_num']= pd.Series([page_num_start]*len(df_tmp_para))\n",
    "        df_tmp_para['par_num']= pd.Series([idx]*len(df_tmp_para))\n",
    "        df_tmp_para.drop(list(range(start_word,end_word)),inplace = True) # drop esiting phrase words\n",
    "        rnd_phrase_words = rnd_phrase.split()\n",
    "        for idx_wrd,word in enumerate(rnd_phrase_words): # insert new phrase words\n",
    "            if idx_wrd == 0:\n",
    "                new_row = [0,page_num_start,idx,word,'B_'+aug_tag,len(rnd_phrase_words)]\n",
    "            else:\n",
    "                new_row = [0,page_num_start,idx,word,'I_'+aug_tag,0]\n",
    "            df_tmp_para = Insert_row_(start_word+idx_wrd, df_tmp_para, new_row)\n",
    "        df_tmp_para.reset_index(inplace= True)\n",
    "        list_df_aug.append(df_tmp_para)\n",
    "    df_augment_all = pd.concat(list_df_aug)\n",
    "    return df_augment_all.reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def augment_org(df_aug_tag,df_all_data,aug_samples,aug_tag,page_num_start=600000):\n",
    "    random.seed(0) \n",
    "    phrases = ['abc pvt ltd',\n",
    "            'xyz pvt ltd',\n",
    "           \n",
    "            ]\n",
    "    list_df_aug = []\n",
    "    for idx in range(aug_samples):\n",
    "        dict_aug_data = {}\n",
    "        rnd_phrase= random.choice(phrases)\n",
    "        df_tmp = df_aug_tag.sample()\n",
    "        df_tmp = df_aug_tag.sample() \n",
    "        idx_page = list(df_tmp['page_num'])[0]\n",
    "        idx_para = list(df_tmp['par_num'])[0]\n",
    "        start_word = list(df_tmp['start_word'])[0]\n",
    "        end_word = list(df_tmp['end_word'])[0]\n",
    "        \n",
    "        df_tmp_para = df_all_data[(df_all_data['page_num']==idx_page) &  (df_all_data['par_num']==idx_para)]\n",
    "        df_tmp_para.reset_index(inplace= True)\n",
    "        print('{}: {} <--> {}'.format(idx,' '.join(list(df_tmp_para.loc[start_word:end_word]['word'])),rnd_phrase))\n",
    "\n",
    "        df_tmp_para['page_num']= pd.Series([page_num_start]*len(df_tmp_para))\n",
    "        df_tmp_para['par_num']= pd.Series([idx]*len(df_tmp_para))\n",
    "        df_tmp_para.drop(list(range(start_word,end_word)),inplace = True) # drop esiting phrase words\n",
    "        rnd_phrase_words = rnd_phrase.split()\n",
    "        for idx_wrd,word in enumerate(rnd_phrase_words): # insert new phrase words\n",
    "            if idx_wrd == 0:\n",
    "                new_row = [0,page_num_start,idx,word,'B_'+aug_tag,len(rnd_phrase_words)]\n",
    "            else:\n",
    "                new_row = [0,page_num_start,idx,word,'I_'+aug_tag,0]\n",
    "            df_tmp_para = Insert_row_(start_word+idx_wrd, df_tmp_para, new_row)\n",
    "        df_tmp_para.reset_index(inplace= True)\n",
    "        list_df_aug.append(df_tmp_para)\n",
    "    df_augment_all = pd.concat(list_df_aug)\n",
    "    return df_augment_all.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augment_tags = ['PRICE','ORG']\n",
    "aug_samples = 150\n",
    "# aug_tag = 'Exclusive_Yes'\n",
    "def get_tag_info_df(aug_tag,df_all_data):\n",
    "    df_aug_tag = df_all_data[df_all_data['tag']=='B_'+aug_tag]\n",
    "    df_aug_tag.reset_index(inplace = True)\n",
    "    list_para = []\n",
    "    list_start_word = []\n",
    "    list_end_word = []\n",
    "    list_start_char = []\n",
    "    list_end_char = []\n",
    "    # list_end,idx_tag_end_char\n",
    "    for index, row in df_aug_tag.iterrows():\n",
    "        idx_page = row['page_num']\n",
    "        idx_para = row['par_num']\n",
    "        df_tmp = df_all_data[(df_all_data['page_num']==idx_page) &  (df_all_data['par_num']==idx_para)]\n",
    "        df_tmp.reset_index(inplace= True)\n",
    "        para = ' '.join(list(df_tmp['word']))\n",
    "        idx_tag_start = df_tmp[df_tmp['tag'] == 'B_'+aug_tag].index[0]\n",
    "        idx_tag_end = idx_tag_start + df_tmp.iloc[idx_tag_start]['tag_words']\n",
    "        list_start =list(df_tmp[0:idx_tag_start]['word']) \n",
    "        list_end =list(df_tmp[0:idx_tag_end]['word']) \n",
    "        idx_tag_start_char = get_char_offset(list_start)\n",
    "        idx_tag_end_char = get_char_offset(list_end)-1\n",
    "        list_end_word.append(idx_tag_end)\n",
    "        list_start_word.append(idx_tag_start)\n",
    "        list_para.append(para)\n",
    "        list_start_char.append(idx_tag_start_char)\n",
    "        list_end_char.append(idx_tag_end_char)\n",
    "\n",
    "    df_aug_tag['para'] = pd.Series(list_para)\n",
    "    df_aug_tag['start_word']= pd.Series(list_start_word)\n",
    "    df_aug_tag['end_word']= pd.Series(list_end_word)\n",
    "    df_aug_tag['start_char'] = pd.Series(list_start_char)\n",
    "    df_aug_tag['end_char'] = pd.Series(list_end_char)\n",
    "    #     offset_tag = df_all_data\n",
    "    #     start = \n",
    "    # len(list_para)\n",
    "\n",
    "\n",
    "    df_aug_tag.drop(['index'], axis=1,inplace=True)\n",
    "\n",
    "    return df_aug_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aug_tag = get_tag_info_df(aug_tag= 'PRICE',df_all_data=df_all_data)\n",
    "df_augment_PRICE = augment_price(df_aug_tag,df_all_data,aug_samples=150,aug_tag= 'PRICE')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aug_tag = get_tag_info_df(aug_tag= 'ORG',df_all_data=df_all_data)\n",
    "df_augment_ORG = augment_org(df_aug_tag,df_all_data,aug_samples=1000,aug_tag= 'ORG')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_augment_all = pd.concat([df_augment_PRICE,df_augment_ORG])\n",
    "df_augment_all.drop(['index'], axis=1,inplace=True)\n",
    "df_augment_all.reset_index(drop=True,inplace =True)\n",
    "df_augment_all.to_excel(\"data/augmented_data.xlsx\",index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_augment_all.drop(['level_0'], axis=1,inplace=True)\n",
    "len(df_augment_all)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
